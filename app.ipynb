{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from flask import Flask, request, jsonify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Charger le dataset\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sélection des variables pertinentes\n",
    "df = df[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "\n",
    "# Transformer la colonne 'Sex' en numérique\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Gérer les valeurs manquantes\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "# Séparer les données en X (features) et y (cible)\n",
    "X = df.drop(columns=['Survived'])\n",
    "y = df['Survived']\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Séparer en données d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6338 - loss: 0.6733 - val_accuracy: 0.7263 - val_loss: 0.6138\n",
      "Epoch 2/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7663 - loss: 0.5823 - val_accuracy: 0.7598 - val_loss: 0.5057\n",
      "Epoch 3/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7959 - loss: 0.4817 - val_accuracy: 0.8045 - val_loss: 0.4489\n",
      "Epoch 4/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8160 - loss: 0.4318 - val_accuracy: 0.8101 - val_loss: 0.4276\n",
      "Epoch 5/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8200 - loss: 0.4240 - val_accuracy: 0.8101 - val_loss: 0.4244\n",
      "Epoch 6/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8106 - loss: 0.4330 - val_accuracy: 0.8101 - val_loss: 0.4236\n",
      "Epoch 7/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8239 - loss: 0.4074 - val_accuracy: 0.8101 - val_loss: 0.4259\n",
      "Epoch 8/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8205 - loss: 0.4311 - val_accuracy: 0.8156 - val_loss: 0.4292\n",
      "Epoch 9/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3960 - val_accuracy: 0.8212 - val_loss: 0.4290\n",
      "Epoch 10/10\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8464 - loss: 0.3807 - val_accuracy: 0.8212 - val_loss: 0.4319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reshape the data to 3D array\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_reshaped, y_train, epochs=10, batch_size=16, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "model.save(\"titanic_lstm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://10.1.169.148:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "C:\\Users\\romai\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [10/Feb/2025 20:12:23] \"GET /predict?Pclass=1&Sex=0&Age=30&SibSp=0&Parch=0&Fare=50%0A HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "BALANCE_FILE = \"balances.json\"\n",
    "\n",
    "# Chargement des soldes et pondérations\n",
    "try:\n",
    "    with open(BALANCE_FILE, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        model_balances = data.get(\"balances\", {\"peer1\": 1000, \"peer2\": 1000, \"peer3\": 1000})\n",
    "        model_weights = data.get(\"weights\", {\"peer1\": 1.0, \"peer2\": 1.0, \"peer3\": 1.0})\n",
    "except FileNotFoundError:\n",
    "    model_balances = {\"peer1\": 1000, \"peer2\": 1000, \"peer3\": 1000}\n",
    "    model_weights = {\"peer1\": 1.0, \"peer2\": 1.0, \"peer3\": 1.0}\n",
    "    with open(BALANCE_FILE, \"w\") as f:\n",
    "        json.dump({\"balances\": model_balances, \"weights\": model_weights}, f)\n",
    "\n",
    "# Sauvegarde des pondérations et soldes\n",
    "def save_model_data():\n",
    "    with open(BALANCE_FILE, \"w\") as f:\n",
    "        json.dump({\"balances\": model_balances, \"weights\": model_weights}, f)\n",
    "\n",
    "@app.route('/predict', methods=['GET'])\n",
    "def predict():\n",
    "    try:\n",
    "        features = []\n",
    "        for f in [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]:\n",
    "            val = request.args.get(f)\n",
    "            if val is None:\n",
    "                return jsonify({\"error\": f\"Missing parameter: {f}\"}), 400\n",
    "            features.append(float(val))\n",
    "\n",
    "        features = scaler.transform([features]).reshape(1, 1, len(features))\n",
    "        prediction = model.predict(features)[0][0]\n",
    "        return jsonify({\"prediction\": int(prediction > 0.5), \"probability\": float(prediction)})\n",
    "    \n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "def update_weights_and_balance(predictions, consensus):\n",
    "    global model_weights, model_balances\n",
    "    for peer, pred in predictions.items():\n",
    "        if model_balances[peer] <= 0:\n",
    "            continue  # Ignorer les modèles désactivés\n",
    "        \n",
    "        error = abs(pred - consensus)\n",
    "        penalty = error * 10  # 10 unités de balance perdues par unité d'erreur\n",
    "        model_weights[peer] = max(0, model_weights[peer] - error * 0.1)\n",
    "        model_balances[peer] = max(0, model_balances[peer] - penalty)\n",
    "\n",
    "    save_model_data()\n",
    "\n",
    "@app.route('/consensus_predict', methods=['GET'])\n",
    "def consensus_predict():\n",
    "    try:\n",
    "        api_urls = {\n",
    "            \"peer1\": \"http://peer1-ngrok-url/predict\",\n",
    "            \"peer2\": \"http://peer2-ngrok-url/predict\",\n",
    "            \"peer3\": \"http://peer3-ngrok-url/predict\"\n",
    "        }\n",
    "        \n",
    "        features = {f: request.args.get(f) for f in [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]}\n",
    "        predictions = {}\n",
    "        weighted_sum = 0\n",
    "        weight_total = 0\n",
    "        \n",
    "        for peer, url in api_urls.items():\n",
    "            if model_balances[peer] <= 0:\n",
    "                continue  # Ne pas interroger les modèles désactivés\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(url, params=features, timeout=2)\n",
    "                response.raise_for_status()\n",
    "                prob = response.json().get(\"probability\", 0)\n",
    "                predictions[peer] = prob\n",
    "                weighted_sum += prob * model_weights[peer]\n",
    "                weight_total += model_weights[peer]\n",
    "            except requests.exceptions.RequestException:\n",
    "                predictions[peer] = 0\n",
    "\n",
    "        consensus_prediction = weighted_sum / weight_total if weight_total > 0 else 0\n",
    "        update_weights_and_balance(predictions, consensus_prediction)\n",
    "        \n",
    "        return jsonify({\n",
    "            \"consensus_prediction\": int(consensus_prediction > 0.5),\n",
    "            \"average_probability\": float(consensus_prediction),\n",
    "            \"model_weights\": model_weights,\n",
    "            \"model_balances\": model_balances\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
